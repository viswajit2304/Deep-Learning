{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94a254e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b747f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations for data preprocessing\n",
    "transform = transforms.Compose([\n",
    "    #transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee69b909",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = ImageFolder('train', transform=transform)\n",
    "test_dataset = ImageFolder('test', transform=transform)\n",
    "valid_dataset = ImageFolder('valid', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50954819",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create DataLoader for each dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a98e2594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes, cl2_feature_maps, hidden_size1, hidden_size2):\n",
    "        super(CNN, self).__init__()\n",
    "        # Convolutional Layer 1\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=4, kernel_size=3, stride=1, padding=1)\n",
    "        # Pooling Layer 1\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # Convolutional Layer 2\n",
    "        self.conv2 = nn.Conv2d(in_channels=4, out_channels=cl2_feature_maps, kernel_size=3, stride=1, padding=1)\n",
    "        # Pooling Layer 2\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # Fully Connected Layer\n",
    "        self.fc = nn.Linear(cl2_feature_maps * 56 * 56, hidden_size1)  # Assuming input size after pooling is 56x56\n",
    "        # Hidden Layer 1\n",
    "        self.hidden1 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        # Hidden Layer 2\n",
    "        self.hidden2 = nn.Linear(hidden_size2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.tanh(self.fc(x))\n",
    "        x = F.tanh(self.hidden1(x))\n",
    "        x = self.hidden2(x)\n",
    "        return x\n",
    "\n",
    "# Hyperparameters\n",
    "num_classes = len(train_dataset.classes)\n",
    "hidden_size1 = 1000  # Size for the first hidden layer\n",
    "hidden_size2 = 50   # Size for the second hidden layer\n",
    "num_epochs = 15\n",
    "learning_rate = 0.001\n",
    "cl2_feature_maps_range = range(4, 5)  # Assuming you want to loop over feature maps from 2 to 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ac08ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***    4   ********\n",
      "Epoch [1/15], Loss: 1.3917403627955724\n",
      "Epoch [2/15], Loss: 1.1742284685846358\n",
      "Epoch [3/15], Loss: 1.053607359765068\n",
      "Epoch [4/15], Loss: 0.9558688818462311\n",
      "Epoch [5/15], Loss: 0.8387132201875959\n",
      "Epoch [6/15], Loss: 0.6429070612740895\n",
      "Epoch [7/15], Loss: 0.44443037254469736\n",
      "Epoch [8/15], Loss: 0.29382025060199557\n",
      "Epoch [9/15], Loss: 0.18809460387343452\n",
      "Epoch [10/15], Loss: 0.10655562224842254\n",
      "Epoch [11/15], Loss: 0.0597305851027606\n",
      "Epoch [12/15], Loss: 0.0703100785908718\n",
      "Epoch [13/15], Loss: 0.07679041244444393\n",
      "Epoch [14/15], Loss: 0.0791295241741907\n",
      "Epoch [15/15], Loss: 0.14218949816293186\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for i in cl2_feature_maps_range:\n",
    "    print(f\"***    {i}   ********\")\n",
    "    cl2_feature_maps = i\n",
    "    model = CNN(num_classes, cl2_feature_maps, hidden_size1, hidden_size2)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)  # Adding weight decay for regularization\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "356e6051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cl2 Feature Maps: 4\n",
      "Training Accuracy: 0.995\n",
      "Validation Accuracy: 0.524\n",
      "Test Accuracy: 0.504\n"
     ]
    }
   ],
   "source": [
    "# Testing and evaluation\n",
    "def calculate_accuracy(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            predictions.extend(predicted.numpy())\n",
    "            true_labels.extend(labels.numpy())\n",
    "    accuracy = correct / total\n",
    "    return accuracy, np.array(predictions), np.array(true_labels)\n",
    "\n",
    "for i in cl2_feature_maps_range:\n",
    "    cl2_feature_maps = i\n",
    "    print(f\"Cl2 Feature Maps: {cl2_feature_maps}\")\n",
    "    \n",
    "    # Training accuracy\n",
    "    train_accuracy, _, _ = calculate_accuracy(train_loader)\n",
    "    print(f\"Training Accuracy: {train_accuracy}\")\n",
    "\n",
    "    # Validation accuracy\n",
    "    valid_accuracy, _, _ = calculate_accuracy(valid_loader)\n",
    "    print(f\"Validation Accuracy: {valid_accuracy}\")\n",
    "\n",
    "    # Testing accuracy\n",
    "    test_accuracy, _, _ = calculate_accuracy(test_loader)\n",
    "    print(f\"Test Accuracy: {test_accuracy}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
